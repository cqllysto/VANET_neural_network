# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NuCDhrJO9Cvlg4rOqsb8rT7nSHJUJ5hB
"""

#############################
# --- Import Libraries  --- #
#############################

!pip install bayesian-optimization

import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
from sklearn.svm import SVC
from sklearn.datasets import load_breast_cancer
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
import warnings
warnings.filterwarnings("ignore")

import math
import numpy as np
from scipy import special
import pandas as pd

from keras import backend as K
from keras.models import Sequential, Model
from keras import layers, regularizers
from keras import Input
from sklearn.preprocessing import MinMaxScaler
from keras.layers import Lambda

import time
import numpy as np
import matplotlib.pyplot as plt
from sklearn.svm import SVC
from sklearn.datasets import load_breast_cancer
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
from bayes_opt import BayesianOptimization, UtilityFunction
import warnings
warnings.filterwarnings("ignore")

import math
from numpy import dot
from scipy import special
t1 = time.perf_counter()
from google.colab import files
import io

# QOS Generator Function Declaration

def qosGenerator(gammap, k, lambdap, Nrp, W0 = 1024, beita = 0.2, Nf_value = 1.2589e-13):

    def SubrSNRC_pi(M=None, re=None, T=None, W0=None, lambdap=None, DIFS=None, sigma=None, *args, **kwargs):

        R = re
        lambda_ = lambdap / 1000000.0
        Ntr = M
        Ncs = Ntr
        Nph = dot(2.0, Ntr) - Ncs
        rho = 1
        rho_old = 0
        pb = 1
        epsilon = 1e-06
        while (abs(rho_old - rho) > epsilon):
            pix = dot(2, T) / (dot(W0, (sigma + dot(pb, T))) + sigma - dot(pb, T) + dot(2, T) + dot(dot(2, (1 - rho)),
                                                                                                    (1 / lambda_ + DIFS)))
            Pxmt = dot((T - DIFS - dot(2, sigma)), pix) / W0 / T + dot(dot(dot((1 - 1 / W0), 2), sigma), pix) / T
            pb1 = 1 - np.exp(dot(- Ntr, Pxmt))
            if (pb1 < 0):
                pb1 = 0
            while (abs(pb1 - pb) > epsilon):
                pix = dot(2, T) / (dot(W0, (sigma + dot(pb, T))) + sigma - dot(pb, T) + dot(2, T) + dot(dot(2, (1 - rho)), (
                        1 / lambda_ + DIFS)))
                Pxmt = dot((T - DIFS - dot(2, sigma)), pix) / W0 / T + dot(dot(dot((1 - 1 / W0), 2), sigma), pix) / T
                pbb = 1 - np.exp(dot(- Ntr, Pxmt))
                if (pbb < 0):
                    pbb = 0
                pb1 = pb
                pb = pbb
            pb = pb1
            qb = 1 - (1 - pb) ** (dot((T + DIFS), W0) / (T - DIFS + dot(dot(2, sigma), W0)))
            mu_tem = 2 / (dot(dot((sigma + dot(pb, T)), (1 - dot((1 - qb), (1 - rho)))), (W0 - 1)) + dot(2, T))
            rho_old = rho
            if (lambda_ < mu_tem):
                rho = lambda_ / mu_tem
            else:
                rho = 1
        qb = 1 - (1 - pb) ** (dot((T + DIFS), W0) / (T - DIFS + dot(dot(2, sigma), W0)))
        mu = 2 / (dot(dot((sigma + dot(pb, T)), (1 - dot((1 - qb), (1 - rho)))), (W0 - 1)) + dot(2, T))
        # ==========================================================================
        var_PA = 0
        mean_service = 1 / mu / 1000000.0
        var_service = dot((dot(dot(dot((W0 - 1), (dot(2, W0) - 1)), (sigma + dot(pb, T)) ** 2),
                            (1 - dot((1 - qb), (1 - rho)))) / 6 + dot(
            dot((W0 - 1), (dot(var_PA, pb) + dot(dot(T ** 2, pb), (1 - pb)) + dot(dot(2, T), (sigma + dot(pb, T))))),
            (1 - dot((1 - qb), (1 - rho)))) / 2 + var_PA + T ** 2 - (
                                dot(dot((sigma + dot(pb, T)), (1 - dot((1 - qb), (1 - rho)))),
                                    (W0 - 1)) / 2 + T) ** 2), (1 / 1000000.0) ** 2)
        # ==========================================================================
        EDq = dot(lambdap, (var_service + mean_service ** 2)) / (dot(2, (1 - rho)))
        ED = EDq + mean_service
        # ==========================================================================
        pi_XMT = dot(2, T) / (
                dot((rho + dot(qb, (1 - rho))), (dot((sigma + dot(pb, T)), W0) + (sigma - dot(pb, T)))) + dot(2,
                                                                                                            T) + dot(
            dot(2, (1 - rho)), (1 / lambda_ + DIFS)))
        P_XMT = dot(pi_XMT, (T - DIFS + dot(dot(2, sigma), W0))) / (dot(W0, T))
        # --------------------------------------------------------------------------
        pi_0 = dot(dot(pi_XMT, (rho + dot(qb, (1 - rho)))), sigma) / T
        # ==========================================================================
        pt = dot(dot(pi_XMT, 2), (T - DIFS)) / T
        return pt, pi_0, pi_XMT, ED


    if __name__ == '__main__':
        pass


    #initialization
    ds = 100      #change from 350
    R = 100
    #beita = 0.2
    M = 1
    gammap=gammap ##########NEW#ADD###############

    Band = 20
    PAn = 1600
    nds = 52
    cr = 5 / 6
    nhmac = 64
    tbdh = 4
    kb = Band / 5
    sigma = 21 / kb
    SIFS = 64 / kb
    AIFS = SIFS + dot(2, sigma)
    tsym = 16 / kb
    tpre = math.floor(160 / kb)
    nmimo = 1 ##### MIMO rate = 2在原来的代码里

    #Payload duration calculation
    Ts = tpre + AIFS + dot(tsym, np.ceil((dot(PAn, 8) + nhmac) / (dot(dot(k, nds), cr)))) + tbdh
    Ts = Ts / nmimo
    Tp = (Ts - tpre - AIFS - tbdh)
    T = Ts + dot(Tp, (Nrp))

    #Network parameter settingup
    d0 = 1
    dc = 102
    Pt = 0.28183815
    Rth = 1.3969e-15
    Pth = 1.3969e-15
    Inta = 1.63726e-05
    Nf = Nf_value          #dot(0.0001, 1.2589e-13)  ################NEW#ADD##################
    alfa1 = 2.56
    alfa2 = 6.34
    rE = dot((gammap) ** (1 / alfa2), R)
    sigma1 = 3.9
    sigma2 = 5.2

    M = round(dot(dot(2, rE), beita)) ################NEW#ADD##################
    #The Density of vehicles on the road
    #beta(M)=beita   #beta(M)=M/R/2 旧代码

    #Call the subroutine to derive pt, pi_0, and pi_{XMT} from Eq. (7)
    pt, pi_0, pi_XMT, ED = SubrSNRC_pi(M, rE, T, W0, lambdap, AIFS, sigma)
    #Calculate QoS metrics
    #256QAM with 8 dB Gain
    ed = ED
    pt = dot(pt, (1 + 1 / (Nrp + 1))) / 2
    B1 = Band ####################原来是B1=20
    Dr = 68.82
    Sr = np.arange(0, 1300, 0.5)
    EbNo = dot(dot(Sr, 10 ** 0.8), B1) / Dr
    MM = 2 ** k
    x3 = np.sqrt(dot(dot(3, k), EbNo) / (MM - 1))
    Pbg = dot(dot(dot((4 / k), (1 - 1 / np.sqrt(MM))), (1 / 2)), special.erfc(x3 / math.sqrt(2)))
    FER = 1 - (1 - Pbg) ** (dot(PAn, 8))

    if ds <= dc:
        sigma = sigma1
    else:
        sigma = sigma2
    theta = 0

    CSINR=np.ones(2600)
    dt=np.ones(2600)
    while theta < 1300:
        theta1 = int(1 + np.floor(dot(theta, 2))) - 1
        if ds <= dc:
            DImax = dot((theta) ** (1 / alfa1), ds)
            if DImax > dc:
                DImax = dot(dot((theta) ** (1 / alfa2), (ds / dc) ** (alfa1 / alfa2)), dc)
        else:
            DImax = dot(dot((theta) ** (1 / alfa1), (ds / dc) ** (alfa2 / alfa1)), dc)
            if DImax > dc:
                DImax = dot((theta) ** (1 / alfa2), ds)
        if ds <= dc:
            DImax2 = dot((dot(2, theta)) ** (1 / alfa1), ds)
            if DImax2 > dc:
                DImax2 = dot(dot((dot(2, theta)) ** (1 / alfa2), (ds / dc) ** (alfa1 / alfa2)), dc)
        else:
            DImax2 = dot(dot((dot(2, theta)) ** (1 / alfa1), (ds / dc) ** (alfa2 / alfa1)), dc)
            if DImax2 > dc:
                DImax2 = dot((dot(2, theta)) ** (1 / alfa2), ds)
        N_ht = max(DImax - rE + ds, 0) + max(DImax - rE - ds, 0)
        Psh = 1 - np.exp(dot(dot(- pt, N_ht), beita))
        N_ht21 = (max(DImax2 - max(DImax, rE + ds), 0))
        N_ht22 = (max(DImax2 - max(DImax, rE - ds), 0))
        Phc = dot((1 - np.exp(dot(dot(- pt, N_ht21), beita))), (1 - np.exp(dot(dot(- pt, N_ht22), beita))))
        Ncc = min(DImax, rE - ds) + min(DImax, rE + ds)
        Pcc = 1 - np.exp(dot(dot(- pi_0, Ncc), beita))
        Pt1=gammap*Pt ################NEW#ADD##################

        if ds <= dc:
            Pr = dot(dot(Pt1, Inta), (d0 / ds) ** alfa1)################NEW#ADD##################change Pt to Pt1
        else:
            Pr = dot(dot(dot(Pt1, Inta), (d0 / dc) ** alfa1), (dc / ds) ** alfa2)################NEW#ADD##################change Pt to Pt1
        Prdb = dot(10, np.log10(Pr))
        Fn = dot(1 / 2, (1 - special.erf((Prdb - dot(10, np.log10(dot(Nf, theta)))) / 2 ** (1 / 2) / sigma)))

        Prth = dot(1 / 2, (1 - special.erf((Prdb - dot(10, np.log10(Rth))) / 2 ** (1 / 2) / sigma)))
        CSINR[theta1] = 1 - dot(dot(dot((1 - Psh), (1 - Phc)), (1 - Pcc)), (1 - Fn))
        dt[theta1] = theta
        theta = theta + 0.5

    #Calculate the dFSINR
    dFSINR = np.diff(CSINR) / np.diff(dt)

    #Calculate the integral
    sum = 0
    for th in range(1, 2598 + 1):   # Might be arange(1, 2598+1, 1)
        num = dot(dot(FER[th - 1], dFSINR[th - 1]), 0.5)
        sum = sum + num


    Integration = sum
    tPRP = dot((1 - Integration), (1 - Prth))

    #Transmission capacity and throughput
    Pdc = 1 - np.exp(dot(dot(dot(- pi_0, 2), beita), rE))################NEW#ADD##################change R to rE
    Pdh = (1 - np.exp(dot(dot(- pt, rE), beita) / 2)) ** 2################NEW#ADD##################change R to rE
    TC = dot(dot(dot(dot(2, lambdap), rE), beita), (1 - Pdc / 2 - Pdh / 2))################NEW#ADD##################change R to rE
    CBR = dot(dot(TC, T), 1e-06)
    cbr = CBR
    Thruput = dot(CBR, (Nrp + 1))

    #PRP with repetitions
    ss = 0
    for i in range (1, int(Nrp) + 1 + 1):  #(1, Nrp.astype(np.int64) + 1 + 1):
        ss = ss + dot(dot(special.comb(Nrp + 1, i), tPRP ** i), (1 - tPRP) ** (Nrp + 1 - i))
    PRP = ss


    #print('prp:%f\n'% PRP)
    #print('ed:%f\n'% ed)
    #print('cbr:%f'% CBR)



    #########################
    # ---   constrain   --- #
    #########################

    #penalty = 1000000  #1000000
    #if (PRP >= 0.999) & (ed <= 0.01):
    #    return -CBR,PRP,ed
    #else:
    return -CBR

# File Upload

uploaded = files.upload()
#df = pd.read_csv('/final_data.csv')
final_data = list(uploaded.keys())[0]
df = pd.read_csv(io.BytesIO(uploaded[final_data]))
#df = final_data.copy()
#df = df.drop('Index',axis=1)
df.head()

# Cleaning the Data

# 75% of the data is selected
train_df = df.sample(frac=0.75, random_state=4)

# it drops the training data
# from the original dataframe
val_df = df.drop(train_df.index)

# calling to (0,1) range
max_val = df.max(axis= 0)
min_val = df.min(axis= 0)


range = max_val - min_val
train_df = (train_df - min_val)/(range)

val_df =  (val_df- min_val)/range


# now let's separate the targets and labels
X_train = train_df.drop(['CBR','PRP','ed'], axis=1)

X_val = val_df.drop(['CBR','PRP','ed'], axis=1)

y_train = train_df[['CBR']].copy()

y_val = val_df[['CBR']].copy()

# We'll need to pass the shape
# of features/inputs as an argument
# in our model, so let's define a variable
# to save it.
input_shape = [X_train.shape[1]] # How many inputs we have

# print(input_shape, min_val, max_val, range)

#############################################
#       NEURAL NETWORK MODEL
#############################################

model = tf.keras.Sequential([
    tf.keras.layers.GaussianNoise(0.001, seed=None),
    tf.keras.layers.Dense(units=64, activation='relu',kernel_regularizer=tf.keras.regularizers.L2(0.001), input_shape=input_shape),
    tf.keras.layers.Dense(units=128, activation='relu'),
    tf.keras.layers.Dense(units=32, activation='relu'),
    tf.keras.layers.Dense(units=1)
])



# adam optimizer works pretty well for
# all kinds of problems and is a good starting point
model.compile(optimizer='adam',

              # MAE error is good for
              # numerical predictions
              loss='mae')

losses = model.fit(X_train, y_train,

                   validation_data=(X_val, y_val),

                   # it will use 'batch_size' number
                   # of examples per example
                   batch_size=256,
                   epochs=500,  # total epoch

                   )

# Visualizing training Vs Validation Loss

loss_df = pd.DataFrame(losses.history)

# history stores the loss/val
# loss in each epoch

# loss_df is a dataframe which
# contains the losses so we can
# plot it to visualize our model training
loss_df.loc[:,['loss','val_loss']].plot()

# Making the validation cbr into a pandas dataframe
y_val = pd.DataFrame(y_val)

# Making the valdiation cbr into a list
y_val = y_val.values.tolist()

# Making a new dataframe called results as the neural networks prediction of validation cbr using the validation inputs
results = model.predict(X_val.iloc[:,:])

# Turning the dataframe into a Pandas list
results = pd.DataFrame(results)
results = results.values.tolist()

# Saving the neural network predicted cbr and inputs used to a csv file
# Mostly just dataframe manipulation so that the CSV file has inputs and predicted output
results = [i[0] for i in results]
y_val = pd.DataFrame(y_val).to_numpy()
results = pd.DataFrame(results).to_numpy()
values = np.stack((y_val[:,0], results[:,0].T), axis=1)

pd.DataFrame(values).to_csv('values.csv')

# Calculating the error in the neural network manually

list_array = list(np.arange(0,len(y_val)))
sum:float = 0.0
dif:float = 0.0

# For loop that calculates the error of the neural network
for i in list_array:
  sum += abs((results[i]-y_val[i])/y_val[i])*100
  dif += abs(results[i]-y_val[i])
avg_error = sum/(len(list_array))
dif = dif/(len(list_array))
print(avg_error,dif)

def neural_network(gammap, k, lambdap, Nrp):
    # Reshape the inputs into the format expected by the neural network
    inputs = np.array([[gammap, k, lambdap, Nrp]])
    max_val = inputs.max(axis=1)
    min_val = inputs.min(axis=1)

    range = max_val - min_val
    inputs = (inputs - min_val)/(range)

    # Pass the inputs through the neural network to get the output
    output = model.predict(inputs)
    output = 0.016649841 + output*1.138632308

    if output[0][0] <= 0:
      return qosGenerator(gammap, k, lambdap, Nrp)

      # Force to meet QOS requirements

    else:
      return -output[0][0]
      # Return the output as a scalar value
      #if PRP_or_ED(gammap, k, lambdap, Nrp) == 1:
        #return -output[0][0]
      #else:
        #return -1000

    #if PRP <= 0.995:
    #  return -100
    #else:
    #  if output[0][0] <= 0:
    #    return -100
    #  else:
    #    return -output[0][0]

# Optimizing the surrogate function
# Create the optimizer. The black box function to optimize is not
# specified here, as we will call that function directly later
optimizer = BayesianOptimization(f = neural_network,
                                 pbounds = {'gammap': [1,10], 'k': [6,10], 'lambdap': [1, 20], 'Nrp': [1, 10]},
                                 verbose = 2, random_state = 1234,
                                 allow_duplicate_points=True)

# let the init_points = 5
# let the iteration = 100

a = optimizer.maximize(init_points = 1, n_iter = 100)
t2 = time.perf_counter()
print("Best result: {}; f(x) = {}.".format(optimizer.max["params"], -1 * optimizer.max["target"]),'time taken to run:',t2-t1)
best = optimizer.max["target"]

qosGenerator(1,10,1,1)